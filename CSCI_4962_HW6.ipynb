{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8FKzGS5GXSYXoGQpS3tck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaoshaoyc/CSCI-4962/blob/main/CSCI_4962_HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1(50 points)**: We discussed how we can formulate RL problems as an MDP. Describe any\n",
        "real-world application that can be formulated as an MDP. Describe the state space, action\n",
        "space, transition model, and rewards for that problem. You do not need to be precise in the\n",
        "description of the transition model and reward (no formula is needed). Qualitative description\n",
        "is enough."
      ],
      "metadata": {
        "id": "eYjFvw52_HsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One real-world application that can be formulated as an MDP could be the dynamic treatment regimes for critical care such as Sepsis and Anesthesia. Dynamic treatment regimes are suitable for RL because we need to adapt our future treatment plans based on the reflection of our patients giving the current treatment. The **state space** for dynamic treatment regimes could be the health metrics of the patient such as body temperature, heart rate, blood pressure, oxygen content of blood, and the medicine levels. The **action space** could be the combinations of the treatments that is available (medicine, surgery). After applying new treatment, patients' condition will be transited to a new status, which defines our **trainsition model**. Finally, the **rewards** of the problem could be the speed and the level of recovery of the patient. (i.e. 100 points if the patient has a full recovery quickly without side effect, and 10 points if the patient has a full recovery quickly with some side effects) With a large population of patients, RL could give the best treatment under patients' current circumstances.\n",
        "\n",
        "**Source:**\n",
        "\n",
        "https://arxiv.org/pdf/1908.08796.pdf"
      ],
      "metadata": {
        "id": "Kp7JDGPz_Kp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------"
      ],
      "metadata": {
        "id": "UgKFj27bCi4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2(50 points)**: RL is used in various sectors - Healthcare, recommender systems and trading\n",
        "are a few of those. Pick one of the three areas. Explain one of the problems in any of these\n",
        "domains that can be more effectively solved by reinforcement learning. Find an open-source\n",
        "project (if any) that has addressed this problem. Explain this project in detail."
      ],
      "metadata": {
        "id": "6LNc3W6H_Lvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the realm of healthcare, the problem of landmark detection in brain images can be effectively solved by reinforce learning. Although CNN methods can also be used to solve the problem, RL methods outperform in two ways:\n",
        "1. RL based methods can perform a non-exhaustive search, which doesn't require to calculate the entire 3d image, boosting the inference speed.\n",
        "2. RL can be data efficient since we can place our agents at different starting locations.\n",
        "\n",
        "One open-source project that takes advantage of RL to sole the problem is the Communicative Multi-Agent Reinforce Learning (C-MARL) system. The model utilized a communicative DQN-based RL agents for the detection of anatomical landmarks in the brain images, achieving a performance better than CNN models. The state space is defined as regions of interest (ROI) of size 45x45x45 voxels, and the agent will reach terminate state if it oscillate around a target point (which means the agent has found the target). The action space is defined as movement (left, right, up, down, forward, or backward) and level of scales (1mm, 2mm, 3mm bounding box). The reward is defined as the euclidean distance between the center of the bounding box and the ground truth.\n",
        "\n",
        "**Source:**\n",
        "\n",
        "https://github.com/gml16/rl-medical\n",
        "\n",
        "https://arxiv.org/pdf/2008.08055.pdf\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_16xeU2Q4UAt"
      }
    }
  ]
}